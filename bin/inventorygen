#!/usr/bin/env python
import argparse
import datetime
import os
import re
import sys
import logging

import yaml
from utils.inventory import Inventory, PaperInfo


logger = logging.getLogger(__name__)

# supported date formats
DATE_FORMATS = [
    "%Y-%m-%d",
    "%Y_%m_%d",
    "%Y"
]


# Setup logging for the application
def configure_logging():
    handlers = []
    handlers.append(logging.StreamHandler(sys.stdout))
    handlers.append(logging.FileHandler('inventorygen.log', 'w'))
    logging.basicConfig(handlers=handlers, level=logging.INFO,
                        style='{',
                        format="{asctime} | {levelname} | {name} | {module} | {message}")


# get the paper name, which is the last component of the path given in the -data-path argument
def get_paper_name(data_dir: str):
    return os.path.basename(data_dir)


# returns the config section for a given date or the default config if
def get_year_conf(date: datetime.date, conf: dict):
    if date is None:
        return conf['default']
    for year_conf in conf['yearconf']:
        if date >= year_conf['from'] and date <= year_conf['to']:
            return year_conf
    return conf['default']


# checks if the file is a tif, jp2 or pdf. Only checks the filename wihtout actually reading the file
def is_supported_file_format(filename: str):
    return re.match(r".*\.(?:tif|jp2|pdf)", filename) is not None


# returns the number of files in 'filenames' that are of a supported type
def contains_supported_files(filenames: list):
    count = 0
    for filename in filenames:
        if is_supported_file_format(filename):
            count += 1
    return count


# Tries to parse the date using one of the format listed in DATE_FORMATS
def parse_to_date(repr: str):
    for date_format in DATE_FORMATS:
        try:
            doc_date = datetime.datetime.strptime(repr, date_format).date()
        except ValueError:
            pass
        else:
            return doc_date


# tries to parse the filename t find a pattern that looks like a date
# Starts by removing the file extension (right-most '.' and everything after) and any leading non-digit character
# tries then to parse the remaining filename as well as the digits sequences to a date
def extract_date(filename: str):
    filename = filename[:filename.rfind('.')]  # remove file extension
    # remove any non-digit char at the beginning of the filename
    for i, c in zip(range(len(filename)), filename):
        if c.isdigit():
            filename = filename[i:]
            break

    digits_sequences = list()
    current_digits_seq = str()
    for char in filename:
        if char.isdigit():
            current_digits_seq += char
        elif current_digits_seq:
            digits_sequences.append(current_digits_seq)
            current_digits_seq = str()
    if current_digits_seq:
        digits_sequences.append(current_digits_seq)

    doc_date = parse_to_date(filename)

    if doc_date:
        return doc_date

    date_join = "-".join(digits_sequences[:min(3, len(digits_sequences))])
    doc_date = parse_to_date(date_join)
    if doc_date:
        return doc_date

    doc_date = parse_to_date(digits_sequences[0])
    if doc_date:
        return doc_date
    return None


# build a Paperinfo from extracted data
def prepare_paperInfo(config, doc_date: datetime.date, paper_name: str, tif_count: int):
    year_conf = get_year_conf(doc_date, config)
    return PaperInfo(type=year_conf.get('type'), paperID=paper_name,
                     callNumber=year_conf.get('callNumber'),
                     title=year_conf.get('title'),
                     titleCollection=year_conf.get('titleCollection'),
                     subTitle=year_conf.get('subTitle'),
                     printer=year_conf.get('printer'),
                     publisher=year_conf.get('publisher'),
                     day=doc_date.strftime("%d") if doc_date else None,
                     month=doc_date.strftime("%m") if doc_date else None,
                     year=doc_date.strftime("%Y") if doc_date else None,
                     pages=f"{tif_count}",
                     languages=year_conf.get('languages'))


# find document and group them by date in the filename.
# returns a dict() with the number of page per document date.
def find_documents_in_dir(directory: str, files: list):
    doc_count = dict()
    for file in files:
        file_date = extract_date(file)
        if file_date is None:
            logger.warning(f"Couldn't parse date in file {file}")
        elif file_date not in doc_count:
            tmp = list()
            doc_count[file_date] = tmp
        doc_count[file_date].append(file)
    return doc_count


# setup cli arguments, logging and config
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    required = parser.add_argument_group("required arguments")
    required.add_argument("-c", "--config-file", type=str, required=True,
                          help="Specify configuration file.")
    parser.add_argument("-d", "--data-path",
                        type=str, default=None,
                        help="Directory containing data to parse. Overrides datapath set in the config file")
    parser.add_argument("-p", "--project-name", type=str, default=None,
                        help="Project name, Overrides project set in the config file")
    parser.add_argument("-o", "--output-file",
                        type=str, default=None,
                        help="Output inventory file")
    args = parser.parse_args()

    configure_logging()

    # parse config file, override config with cli args if provided
    if not os.path.isfile(args.config_file):
        logger.critical(f"Specified config file {args.config_file} doesn't exist. Aborting.")
        sys.exit(1)
    with open(args.config_file) as f:
        config = yaml.safe_load(f)
    if args.data_path:
        config['datapath'] = args.data_path
    if args.project_name:
        config['project'] = args.project_name
    if args.output_file:
        config['outputfile'] = args.output_file
    if not os.path.isabs(config['outputfile']):
        config['outputfile'] = os.path.join(os.getcwd(), config['outputfile'])

    # check if data_dir is valid
    data_dir = config['datapath']
    if not os.path.isdir(data_dir):
        logger.critical(f"Specified data directory {data_dir} doesn't exist. Aborting.")
        sys.exit(1)

    # Build the inventory object, then search for directories with supported files that are leaf directories
    # if a directory contains relevant documents, extract properties and add them to the inventory object
    paper_name = get_paper_name(data_dir)
    inventory = Inventory(config['project'])
    for directory, subdirs, files in os.walk(data_dir):
        tif_count = contains_supported_files(files)
        logger.debug(f"Found tif files in {directory}")
        if tif_count and not subdirs:
            documents = find_documents_in_dir(directory, files)
            for document, docfiles in documents.items():
                paperInfo = prepare_paperInfo(config, document, paper_name, len(docfiles))
                doc_id = f"{paper_name}_{document}"
                doc_id = doc_id.replace(" ", "_")
                inventory.add_document(doc_id, paperInfo)
    # write the inventory to a file
    if len(inventory):
        logger.info(f"Inventory file created at {config['outputfile']}")
        inventory.write(config['outputfile'])
